{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notebook com exemplo de algumas funcionalidades que o projeto pretende implementar (em andamento....)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Coleta dos tweets com tweepy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.7/site-packages/pandas/compat/_optional.py:138: UserWarning: Pandas requires version '2.7.0' or newer of 'numexpr' (version '2.6.9' currently installed).\n",
      "  warnings.warn(msg, UserWarning)\n"
     ]
    }
   ],
   "source": [
    "import tweepy\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tqdm.auto import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Para coletar tweets via API do twitter e necessario ter uma conta de desenvolvedor na plataforma\n",
    "# Esse arquivo .txt constam minhas chaves e senhas pra acesso, nao disponibilizados no repositorio,\n",
    "# respeitando os termos de uso do twitter e garantindo a privacidade da minha conta\n",
    "\n",
    "with open('./twitter_keys.txt', 'r') as f:\n",
    "    api_key = f.readline().strip('\\n')\n",
    "    api_key_secret = f.readline().strip('\\n')\n",
    "    acess_token = f.readline().strip('\\n')\n",
    "    acess_token_secret = f.readline().strip('\\n')\n",
    "\n",
    "\n",
    "auth = tweepy.OAuthHandler(api_key, api_key_secret)\n",
    "auth.set_access_token(acess_token, acess_token_secret)\n",
    "\n",
    "api = tweepy.API(auth)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "palavras_chave_hashtags = input(\n",
    "    'Insira aqui as palavras chaves e/ou hashtags relacionadas ao tema de interesse separados por espa√ßos:'\n",
    "    )\n",
    "'''\n",
    "\n",
    "palavras_chave_hashtags = 'lula alckmin' # configurando palavras chaves do exemplo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "lista_query = []\n",
    "for palavra in palavras_chave_hashtags.split():\n",
    "    query_string = palavra + ' -filter:retweets' # excluindo rts da coleta porque sao textos repetidos\n",
    "    lista_query.append(query_string)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Coletando tweets com o termo: lula\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 500/500 [00:20<00:00, 24.93it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Coletando tweets com o termo: alckmin\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 500/500 [00:19<00:00, 26.04it/s]\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "Transformando json dos tweets em dicts e depois em dataframes e selecionando atributos de interesse para analise\n",
    "'''\n",
    "\n",
    "\n",
    "dict_features_ = {}\n",
    "n = 0\n",
    "\n",
    "limite = 1_000 # limitando quantidade para nao sobrecarregar as buscas\n",
    "qtd_por_palavra = limite/len(lista_query)\n",
    "\n",
    "for query_string in lista_query:\n",
    "\n",
    "    print(f'Coletando tweets com o termo: {query_string.split()[0]}\\n')\n",
    "\n",
    "    tweets = tweepy.Cursor(api.search_tweets, q=query_string).items(qtd_por_palavra)\n",
    "    \n",
    "    for twt in tqdm(tweets, total=int(qtd_por_palavra)):\n",
    "        d = twt._json\n",
    "        dict_features_[n] = {}\n",
    "\n",
    "        dict_features_[n]['created_at'] = d['created_at']\n",
    "        dict_features_[n]['hashtags'] = d['entities']['hashtags']#['text']\n",
    "        dict_features_[n]['text'] = d['text']\n",
    "        dict_features_[n]['tweet_id'] = d['id']\n",
    "        dict_features_[n]['user_description'] = d['user']['description']\n",
    "        dict_features_[n]['user_id'] = d['user']['id']\n",
    "        dict_features_[n]['user_name'] = d['user']['name']\n",
    "        dict_features_[n]['user_@'] = d['user']['screen_name']\n",
    "\n",
    "\n",
    "        dict_features_[n]['reply_tweet_id'] = d['in_reply_to_status_id']\n",
    "        dict_features_[n]['reply_user_@'] = d['in_reply_to_screen_name']\n",
    "        dict_features_[n]['reply_user_id'] = d['in_reply_to_user_id']\n",
    "\n",
    "        n+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>hashtags</th>\n",
       "      <th>user_description</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>A prova de que n√£o importa o grau de instru√ß√£o...</td>\n",
       "      <td>[]</td>\n",
       "      <td>üê∑</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>As pessoas est√£o se perguntando \"Quantos votos...</td>\n",
       "      <td>[]</td>\n",
       "      <td>Paix√£o demais cega</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>A estrat√©gia de Bolsonaro e a Queda de Lula ht...</td>\n",
       "      <td>[]</td>\n",
       "      <td>A esquerda √© o pr√≥prio mal na terra! Com corag...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>@raismach @andrecdforyou @g1 Manda o Lula para...</td>\n",
       "      <td>[]</td>\n",
       "      <td>Ainda q eu ande pelo vale da sombra da morte n...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>@Sidsto @Gerson72340523 @safbf Tudo a ver. Por...</td>\n",
       "      <td>[]</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>@CMonteroOficial Con una visita del Nobel de l...</td>\n",
       "      <td>[]</td>\n",
       "      <td>Premio Nacional de Ciencia y Tecnologia. Menci...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>@correio Alckmin √© esperto! Quer ser vice de L...</td>\n",
       "      <td>[]</td>\n",
       "      <td>üáßüá∑\\nFan account\\nInSomnia\\nLittle Black Stars</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Eu quero dormir e acordar em 2023 quando o Lul...</td>\n",
       "      <td>[]</td>\n",
       "      <td>~ Artist Wannabe ~\\n~ Candle Maker ~\\n~ Natura...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>vai pabllo lance o Lula‚Äôs PT Remix</td>\n",
       "      <td>[]</td>\n",
       "      <td>se eu for eu vou</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>@silva_gustavo @alanmfreitas @jfdemocracia @sa...</td>\n",
       "      <td>[]</td>\n",
       "      <td>Ela|Dela ‚ñ™Ô∏é Bissexual üè≥Ô∏è‚Äçüåà                    ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text hashtags  \\\n",
       "0  A prova de que n√£o importa o grau de instru√ß√£o...       []   \n",
       "1  As pessoas est√£o se perguntando \"Quantos votos...       []   \n",
       "2  A estrat√©gia de Bolsonaro e a Queda de Lula ht...       []   \n",
       "3  @raismach @andrecdforyou @g1 Manda o Lula para...       []   \n",
       "4  @Sidsto @Gerson72340523 @safbf Tudo a ver. Por...       []   \n",
       "5  @CMonteroOficial Con una visita del Nobel de l...       []   \n",
       "6  @correio Alckmin √© esperto! Quer ser vice de L...       []   \n",
       "7  Eu quero dormir e acordar em 2023 quando o Lul...       []   \n",
       "8                 vai pabllo lance o Lula‚Äôs PT Remix       []   \n",
       "9  @silva_gustavo @alanmfreitas @jfdemocracia @sa...       []   \n",
       "\n",
       "                                    user_description  \n",
       "0                                                  üê∑  \n",
       "1                                 Paix√£o demais cega  \n",
       "2  A esquerda √© o pr√≥prio mal na terra! Com corag...  \n",
       "3  Ainda q eu ande pelo vale da sombra da morte n...  \n",
       "4                                                     \n",
       "5  Premio Nacional de Ciencia y Tecnologia. Menci...  \n",
       "6      üáßüá∑\\nFan account\\nInSomnia\\nLittle Black Stars  \n",
       "7  ~ Artist Wannabe ~\\n~ Candle Maker ~\\n~ Natura...  \n",
       "8                                   se eu for eu vou  \n",
       "9  Ela|Dela ‚ñ™Ô∏é Bissexual üè≥Ô∏è‚Äçüåà                    ...  "
      ]
     },
     "execution_count": 141,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_tweets = pd.DataFrame.from_dict(dict_features_, orient='index')#.to_csv(f'./tweets_lula_alckmin.csv', index=False)\n",
    " # selecionando principais features para usar na analise\n",
    "df_tweets = df_tweets[['text', 'hashtags', 'user_description', 'user_name']]\n",
    "df_tweets[['text', 'hashtags', 'user_description']].head(10) # omitindo os nomes por questoes de privacidade"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'text': 'Lula', 'indices': [46, 51]}]"
      ]
     },
     "execution_count": 147,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# as hashtags vem como um dict, com string e localizacao da hashtag no texto - precisa ser modificada\n",
    "df_tweets['hashtags'].iloc[562]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pre-Processamento dos textos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [],
   "source": [
    "# funcoes auxiliares pra coletar hashtags do texto, bio e nome\n",
    "\n",
    "import re\n",
    "HASHTAG = re.compile(r'#(\\w+)')\n",
    "\n",
    "def hashtags_to_list(x):\n",
    "    try:\n",
    "      if x == []:\n",
    "        x = np.NaN\n",
    "      else:\n",
    "        x = [x[i]['text'] for i in range(len(x))]\n",
    "    except:\n",
    "      x = np.NaN\n",
    "     \n",
    "    return x\n",
    "\n",
    "def get_descriptions_hashtags(d):\n",
    "  if type(d) != str:\n",
    "    return np.nan\n",
    "  else:\n",
    "    list_hashtags = HASHTAG.findall(d)\n",
    "    if len(list_hashtags) > 0:\n",
    "      return list_hashtags\n",
    "    else:\n",
    "      return np.nan\n",
    "\n",
    "\n",
    "def get_username_hashtags(u):\n",
    "  if type(u) != str:\n",
    "    return np.nan\n",
    "  else:\n",
    "    list_hashtags = HASHTAG.findall(u)\n",
    "    if len(list_hashtags) > 0:\n",
    "      return list_hashtags\n",
    "    else:\n",
    "      return np.nan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [],
   "source": [
    "# aplicando as funcoes de hashtags nos dataframes com a abodargem funcional (apply + lambda)\n",
    "\n",
    "df_tweets['hashtags_list'] = df_tweets.apply(lambda x: hashtags_to_list(x['hashtags']), axis=1)\n",
    "df_tweets['descriptions_hashtags'] = df_tweets.apply(lambda x: get_descriptions_hashtags(x['user_description']), axis=1)\n",
    "df_tweets['username_hashtags'] = df_tweets.apply(lambda x: get_username_hashtags(x['user_name']), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /Users/rodrigoludermir/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     /Users/rodrigoludermir/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "# pacotes de pre-processamento para nlp (nltk)\n",
    "import nltk\n",
    "import re\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import RegexpTokenizer\n",
    "nltk.download('stopwords')\n",
    "nltk.download('wordnet')\n",
    "import string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "''''\n",
    "Importante: Como n√£o domino inteiramente as express√µes regulares, algumas dessas express√µes s√£o baseadas em c√≥digos de terceiros, \n",
    "coletados em foruns como Stack Overflow. Mas, friso, me baseiei somente na parte de regex, que facilita bastante uma busca otimizada em strings. \n",
    "A Classe de pre-processamento, no entanto, √© de minha autoria.\n",
    "\n",
    "'''\n",
    "\n",
    "\n",
    "from tqdm import tqdm # indica o tempo/quantidade para finalizar loop\n",
    "\n",
    "class Preprocess():\n",
    "    def __init__(self, lower=True): # lower=True para tornar tokens em letras minusculas\n",
    "        self.STOPWORDS = set(stopwords.words('portuguese')) # as palavras mais comuns da l√≠ngua - \"eu, a, o, aquele, eles, voce, da ...\n",
    "        self.pontuations = string.punctuation # lista de pontua√ß√µes\n",
    "        self.tokenizer = RegexpTokenizer(r'\\w+') # funcao pra tokenizar os textos\n",
    "        self.stemmer = nltk.PorterStemmer() #funcao pra stemmatizar tokens\n",
    "        self.lemmatizer = nltk.WordNetLemmatizer() # funcao pra lemmatizar tokens\n",
    "        self.hashtags = re.compile(r'#[-_.?&~;+=/#0-9A-Za-z]{1,2076}') # regex pra remover hashtags\n",
    "        self.mentions = re.compile(r'@[-_.?&~;+=/#0-9A-Za-z]{1,2076}') # regex pra remover mentions em tweets\n",
    "        self.lower = lower\n",
    "\n",
    "\n",
    "    # removendo stopwords\n",
    "    # retorna a lista de palavras que nao est√£o no conjunto de stopwords, ignorando-as\n",
    "    def cleaning_stopwords(self, text, STOPWORDS):\n",
    "        return \" \".join([word for word in str(text).split() if word not in STOPWORDS])\n",
    "\n",
    "    # removendo puntuacoes\n",
    "    def cleaning_punctuations(self, text, pontuacoes):\n",
    "        translator = str.maketrans('', '', pontuacoes)\n",
    "        return text.translate(translator)\n",
    "\n",
    "    # removendo caracteres repetidos\n",
    "    def cleaning_repeating_char(self, text):\n",
    "        return re.sub(r'(.)\\1+', r'\\1', text)\n",
    "\n",
    "    # removendo email\n",
    "    def cleaning_email(self, text):\n",
    "        return re.sub('@[^\\s]+', ' ', text)\n",
    "\n",
    "    # removendo URL's\n",
    "    def cleaning_URLs(self, text):\n",
    "        return re.sub('((www\\.[^\\s]+)|(https?://[^\\s]+))',' ',text)\n",
    "\n",
    "    # removendo numeros\n",
    "    def cleaning_numbers(self, text):\n",
    "        return re.sub('[0-9]+', '', text)\n",
    "\n",
    "    # Stemming -  reduzir palavras flexionadas\n",
    "    def stemming_on_text(self, data, stm):\n",
    "        text = [stm.stem(word) for word in data]\n",
    "        return data\n",
    "\n",
    "    #Lemmatizer - agrupar as formas flexionadas de uma palavra para uma unica feature\n",
    "    def lemmatizer_on_text(self, data, lm):\n",
    "        text = [lm.lemmatize(word) for word in data]\n",
    "        return data\n",
    "                \n",
    "    # transformando tweet orignal em tweet pre-processado - limpo\n",
    "    def transform(self, texts):\n",
    "        #texts: lista de tweets\n",
    "        tweets_preprocessados = []\n",
    "        for t in tqdm(range(len(texts)), total=len(texts), position=0):\n",
    "\n",
    "            if self.lower:\n",
    "              tweet = texts[t].lower()\n",
    "            else:\n",
    "              tweet = texts[t]\n",
    "            tweet = self.cleaning_stopwords(tweet, self.STOPWORDS)\n",
    "            tweet = self.cleaning_punctuations(tweet, self.pontuations)\n",
    "            tweet = self.cleaning_repeating_char(tweet)\n",
    "            tweet = self.cleaning_email(tweet)\n",
    "            tweet = self.cleaning_URLs(tweet)\n",
    "            tweet = self.cleaning_numbers(tweet)\n",
    "            tweet = self.hashtags.sub(\" \", tweet)\n",
    "            tweet = self.mentions.sub(\" \", tweet)\n",
    "            tweet = self.tokenizer.tokenize(tweet)\n",
    "            tweet = self.stemming_on_text(tweet, self.stemmer)\n",
    "            tweet = self.lemmatizer_on_text(tweet, self.lemmatizer)\n",
    "\n",
    "            tweets_preprocessados.append(tweet)\n",
    "\n",
    "        return tweets_preprocessados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1000/1000 [00:00<00:00, 2926.55it/s]\n",
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1000/1000 [00:00<00:00, 4664.94it/s]\n"
     ]
    }
   ],
   "source": [
    "# preprocessando textos dos tweets e das bios dos usuarios\n",
    "\n",
    "prep = Preprocess()\n",
    "df_tweets['prep_text'] = prep.transform(df_tweets['text'].to_list())\n",
    "df_tweets['pre_description'] = prep.transform(df_tweets['user_description'].to_list())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0      [prova, importa, grau, instru√ß√£o, ser, maucar√°...\n",
       "1      [pesoas, perguntando, quantos, votos, alckmin,...\n",
       "2      [estrat√©gia, bolsonaro, queda, lula, htpstcoye...\n",
       "3      [raismach, andrecdforyou, g, manda, lula, rua,...\n",
       "4      [sidsto, gerson, safbf, tudo, ver, fazer, chap...\n",
       "                             ...                        \n",
       "995    [lula, jantar, alckmin, n√£o, importa, pasado, ...\n",
       "996    [entusiasmo, aliado, encontro, lulalckmin, cli...\n",
       "997    [esperei, chapa, lula, boulos, recebi, lula, a...\n",
       "998    [safbf, n, normalizar, detesto, alckmin, gover...\n",
       "999    [t√°, tudo, bem, pros, lulistas, terem, alckmin...\n",
       "Name: prep_text, Length: 1000, dtype: object"
      ]
     },
     "execution_count": 151,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_tweets['prep_text']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0                                                     []\n",
       "1                                 [paix√£o, demais, cega]\n",
       "2      [esquerda, pr√≥prio, mal, tera, coragem, f√©, to...\n",
       "3      [ainda, q, ande, vale, sombra, morte, temerei,...\n",
       "4                                                     []\n",
       "                             ...                        \n",
       "995    [goi√°s, orgulha, ter, kajuru, senador, sa√∫de, ...\n",
       "996                                                 [ai]\n",
       "997                                  [nada, digno, nota]\n",
       "998    [caipira, paulo, advogada, administrativista, ...\n",
       "999                                                   []\n",
       "Name: pre_description, Length: 1000, dtype: object"
      ]
     },
     "execution_count": 152,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_tweets['pre_description']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Explorando os dados textuais"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "\n",
    "tweets_hashtags = []\n",
    "username_hashtags = []\n",
    "descritpions_hashtags = []\n",
    "\n",
    "for hstg in df_tweets['hashtags_list'].dropna():\n",
    "    if type(hstg) == list:\n",
    "        tweets_hashtags.extend(hstg)\n",
    "    else:\n",
    "        tweets_hashtags.append(hstg)\n",
    "\n",
    "df_user_info = df_tweets.copy()\n",
    "for hstg_d in df_user_info['descriptions_hashtags'].dropna():\n",
    "    if type(hstg_d) == list:\n",
    "        descritpions_hashtags.extend(hstg_d)\n",
    "    else:\n",
    "        descritpions_hashtags.append(hstg_d)\n",
    "        \n",
    "for hstg_u in df_user_info['username_hashtags'].dropna():\n",
    "    if type(hstg_d) == list:\n",
    "        username_hashtags.extend(hstg_u)\n",
    "    else:\n",
    "        username_hashtags.append(hstg_u)\n",
    "    \n",
    "\n",
    "tweets_hashtags_ranked = {k:v for k, v in sorted(Counter(tweets_hashtags).items(), key=lambda x:x[1], reverse=True)}\n",
    "description_hashtags_ranked = {k:v for k, v in sorted(Counter(descritpions_hashtags).items(), key=lambda x:x[1], reverse=True)}\n",
    "username_hashtags_ranked = {k:v for k, v in sorted(Counter(username_hashtags).items(), key=lambda x:x[1], reverse=True)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>EJairOuJaEra</th>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LulaLadrao</th>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LulaNoPrimeiroTurno</th>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Lula</th>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Brasil</th>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CPIdoCirco</th>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>STFVergonhaMundial</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SouLulaSouPT</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LulaEoPToAmorVencera</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>BolsonaroGenocida</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Honduras</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Chile</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Lula2022</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>assangefredom</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Vem3MdoPresidenteLula</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Elesnao</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MoroPresidente2022</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ForaBolsonaroGenocida</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>alagoas</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Bostanaro</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AnuladaMaisUmaPilantragemDaLavajato</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LulaPresidente2022</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LulaLadr√£o</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MoroNaCadeia</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RaquelSantana</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Alckmin</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>bolsonaro</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DoriaPresidente</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>JairOuJaEra</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>empauta</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>panoramaCbn</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                     0\n",
       "EJairOuJaEra                         4\n",
       "LulaLadrao                           3\n",
       "LulaNoPrimeiroTurno                  3\n",
       "Lula                                 3\n",
       "Brasil                               2\n",
       "CPIdoCirco                           2\n",
       "STFVergonhaMundial                   1\n",
       "SouLulaSouPT                         1\n",
       "LulaEoPToAmorVencera                 1\n",
       "BolsonaroGenocida                    1\n",
       "Honduras                             1\n",
       "Chile                                1\n",
       "Lula2022                             1\n",
       "assangefredom                        1\n",
       "Vem3MdoPresidenteLula                1\n",
       "Elesnao                              1\n",
       "MoroPresidente2022                   1\n",
       "ForaBolsonaroGenocida                1\n",
       "alagoas                              1\n",
       "Bostanaro                            1\n",
       "AnuladaMaisUmaPilantragemDaLavajato  1\n",
       "LulaPresidente2022                   1\n",
       "LulaLadr√£o                           1\n",
       "MoroNaCadeia                         1\n",
       "RaquelSantana                        1\n",
       "Alckmin                              1\n",
       "bolsonaro                            1\n",
       "DoriaPresidente                      1\n",
       "JairOuJaEra                          1\n",
       "empauta                              1\n",
       "panoramaCbn                          1"
      ]
     },
     "execution_count": 154,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tweets_htsg = pd.DataFrame.from_dict(tweets_hashtags_ranked, orient='index')\n",
    "tweets_htsg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>ForaBolsonaro</th>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LulaInocente</th>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ForaBozo</th>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Lula2022</th>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Lula</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LulaPresidente</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>„Ç¢„Éâ‰∏≠Êùë</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>BrasilConsciente</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Imunizado</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ForaBolsoMoro</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DoriaPresidente</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Vacine</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MoroPresidente</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  0\n",
       "ForaBolsonaro     2\n",
       "LulaInocente      2\n",
       "ForaBozo          2\n",
       "Lula2022          2\n",
       "Lula              1\n",
       "LulaPresidente    1\n",
       "„Ç¢„Éâ‰∏≠Êùë              1\n",
       "BrasilConsciente  1\n",
       "Imunizado         1\n",
       "ForaBolsoMoro     1\n",
       "DoriaPresidente   1\n",
       "Vacine            1\n",
       "MoroPresidente    1"
      ]
     },
     "execution_count": 155,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "username_htsg = pd.DataFrame.from_dict(username_hashtags_ranked, orient='index')\n",
    "username_htsg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>ForaBolsonaro</th>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Lula2022</th>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SDV</th>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>forabolsonarogenocida</th>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>forabolsonaro</th>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>antifascista</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>antiracista</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Bolsonarolixo</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>JeovaVaiTePegar</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TomeVacina</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>73 rows √ó 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                       0\n",
       "ForaBolsonaro          6\n",
       "Lula2022               5\n",
       "SDV                    5\n",
       "forabolsonarogenocida  3\n",
       "forabolsonaro          3\n",
       "...                   ..\n",
       "antifascista           1\n",
       "antiracista            1\n",
       "Bolsonarolixo          1\n",
       "JeovaVaiTePegar        1\n",
       "TomeVacina             1\n",
       "\n",
       "[73 rows x 1 columns]"
      ]
     },
     "execution_count": 156,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bios_htsg = pd.DataFrame.from_dict(description_hashtags_ranked, orient='index')\n",
    "bios_htsg "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "def get_top_ngrams(corpus, n=None):\n",
    "    corpus = [' '.join(tweet) for tweet in corpus]   \n",
    "    vec = CountVectorizer(ngram_range=(1, 3)).fit(corpus) # de 1 a 3 n-grams \n",
    "    bag_of_words = vec.transform(corpus)\n",
    "    sum_words = bag_of_words.sum(axis=0)\n",
    "    words_freq = [(word, sum_words[0, idx]) for word, idx in vec.vocabulary_.items()]\n",
    "    words_freq =sorted(words_freq, key = lambda x: x[1], reverse=True)\n",
    "    return [[n_gram, freq] for n_gram, freq in words_freq][:200] # seleciona as 200 palavras mais frequentes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ngram</th>\n",
       "      <th>frequencia</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>lula</td>\n",
       "      <td>614</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>alckmin</td>\n",
       "      <td>414</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>vai</td>\n",
       "      <td>95</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>pra</td>\n",
       "      <td>92</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>vice</td>\n",
       "      <td>86</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>195</th>\n",
       "      <td>fabiofaria</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>196</th>\n",
       "      <td>saco</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>197</th>\n",
       "      <td>paulo</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>198</th>\n",
       "      <td>eu</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>199</th>\n",
       "      <td>preocupado</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>200 rows √ó 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          ngram  frequencia\n",
       "0          lula         614\n",
       "1       alckmin         414\n",
       "2           vai          95\n",
       "3           pra          92\n",
       "4          vice          86\n",
       "..          ...         ...\n",
       "195  fabiofaria           7\n",
       "196        saco           7\n",
       "197       paulo           7\n",
       "198          eu           7\n",
       "199  preocupado           7\n",
       "\n",
       "[200 rows x 2 columns]"
      ]
     },
     "execution_count": 157,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(get_top_ngrams(df_tweets['prep_text']), columns=['ngram', 'frequencia'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ngram</th>\n",
       "      <th>frequencia</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>brasil</td>\n",
       "      <td>36</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>esquerda</td>\n",
       "      <td>33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>crist√£o</td>\n",
       "      <td>28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>and</td>\n",
       "      <td>28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>bolsonaro</td>\n",
       "      <td>28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>195</th>\n",
       "      <td>livre</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>196</th>\n",
       "      <td>chamar</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>197</th>\n",
       "      <td>at</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>198</th>\n",
       "      <td>cora√ß√£o</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>199</th>\n",
       "      <td>rj</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>200 rows √ó 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         ngram  frequencia\n",
       "0       brasil          36\n",
       "1     esquerda          33\n",
       "2      crist√£o          28\n",
       "3          and          28\n",
       "4    bolsonaro          28\n",
       "..         ...         ...\n",
       "195      livre           5\n",
       "196     chamar           5\n",
       "197         at           5\n",
       "198    cora√ß√£o           5\n",
       "199         rj           5\n",
       "\n",
       "[200 rows x 2 columns]"
      ]
     },
     "execution_count": 158,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(get_top_ngrams(df_tweets['pre_description']), columns=['ngram', 'frequencia'])"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "398dc28c06ad810e77de546bbdfa897a6ee0b83e59a5207339dda01a7843e01d"
  },
  "kernelspec": {
   "display_name": "Python 3.7.3 64-bit ('base': conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
